{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1717367910745,"user":{"displayName":"GABRIEL CASTRO","userId":"16688170761531860236"},"user_tz":420},"id":"_AkRNSdLaFxq"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18630,"status":"ok","timestamp":1717367929371,"user":{"displayName":"GABRIEL CASTRO","userId":"16688170761531860236"},"user_tz":420},"id":"7SYIXdYh20Ed","outputId":"ff6ea743-e461-4d68-b999-223d176b628d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting swig\n","  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: swig\n","Successfully installed swig-4.2.1\n"]}],"source":["!pip install swig"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152238,"status":"ok","timestamp":1717368081605,"user":{"displayName":"GABRIEL CASTRO","userId":"16688170761531860236"},"user_tz":420},"id":"xfMBm0AeaFxr","outputId":"0209995b-3680-4019-cdba-738ea8c80fa4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Collecting wandb\n","  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.2.1)\n","Collecting gymnasium[box2d]\n","  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107-\u003etorch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click!=8.0.0,\u003e=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting docker-pycreds\u003e=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting gitpython!=3.1.29,\u003e=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n","Requirement already satisfied: protobuf!=4.21.0,\u003c5,\u003e=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Requirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Collecting sentry-sdk\u003e=1.0.0 (from wandb)\n","  Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl (289 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n","Collecting farama-notifications\u003e=0.0.1 (from gymnasium[box2d])\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n","  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pygame\u003e=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n","Requirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six\u003e=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds\u003e=0.4.0-\u003ewandb) (1.16.0)\n","Collecting gitdb\u003c5,\u003e=4.0.1 (from gitpython!=3.1.29,\u003e=1.0.0-\u003ewandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2024.2.2)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch) (2.1.5)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch) (1.3.0)\n","Collecting smmap\u003c6,\u003e=3.0.1 (from gitdb\u003c5,\u003e=4.0.1-\u003egitpython!=3.1.29,\u003e=1.0.0-\u003ewandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: box2d-py\n","  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2376103 sha256=c7589f84416979b825d9e97e673099fb69a2d766299e628d6a78ecca9a827a1d\n","  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n","Successfully built box2d-py\n","Installing collected packages: farama-notifications, box2d-py, smmap, setproctitle, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, docker-pycreds, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, nvidia-cusolver-cu12, gitpython, wandb\n","Successfully installed box2d-py-2.3.5 docker-pycreds-0.4.0 farama-notifications-0.0.4 gitdb-4.0.11 gitpython-3.1.43 gymnasium-0.29.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentry-sdk-2.3.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.0\n"]}],"source":["!pip install numpy torch wandb swig gymnasium[box2d] matplotlib termcolor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"v8Rt1z4C2QhO"},"outputs":[{"ename":"ValueError","evalue":"mount failed","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-4-d5df0069828e\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 2\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         )\n\u001b[0;32m--\u003e 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZP22-jTS2SHt"},"outputs":[],"source":["%cd /content/drive/MyDrive/ECE_2392AS_Project4_V2/Student-Version\\ 2/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mQHWkTt1aFxr"},"outputs":[],"source":["import rl_test\n","from utils import *"]},{"cell_type":"markdown","metadata":{"id":"XFnvqV_xaFxs"},"source":["# Reinforcement Learning Part 1: DQN\n","By Lawrence Liu and Tonmoy Monsoor\n","## Some General Instructions\n","\n","- As before, please keep the names of the layer consistent with what is requested in model.py. Otherwise the test functions will not work\n","\n","- You will need to fill in the model.py, the DQN.py file, the buffer.py file, and the\n","env_wrapper.py\n","\n","DO NOT use Windows for this project, gymnasium does is not supported for windows and installing it will be a pain."]},{"cell_type":"markdown","metadata":{"id":"AxkrCziNaFxs"},"source":["### Introduction to the Enviroment\n","We will be training a DQN agent to play the game of CarRacing. The agent will be trained to play the game using the pixels of the game as an input. The reward structure is as follows for each frame:\n","- -0.1 for each frame\n","- +1000/N where N is the number of tiles visited by the car in the episode\n","\n","The overall goal of this game is to design a agent that is able to play the game with a average test score of above 600. In discrete mode the actions can take 5 actions,\n","- 0: Do Nothing\n","- 1: Turn Left\n","- 2: Turn Right\n","- 3: Accelerate\n","- 4: Brake\n","\n","First let us visualize the game and understand the environment."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ffH7ppbzaFxs"},"outputs":[],"source":["import gymnasium as gym\n","import numpy as np\n","env = gym.make('CarRacing-v2', continuous=False, render_mode='rgb_array')\n","env.np_random = np.random.RandomState(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rOeveuTAaFxt"},"outputs":[],"source":["\n","from IPython.display import HTML\n","\n","frames = []\n","s, _ = env.reset()\n","\n","while True:\n","    a = env.action_space.sample()\n","    s, r, terminated, truncated, _ = env.step(a)\n","    frames.append(s)\n","    if terminated or truncated:\n","        break\n","\n","\n","anim = animate(frames)\n","HTML(anim.to_jshtml())"]},{"cell_type":"markdown","metadata":{"id":"s-YRsut6aFxt"},"source":["So a couple things we can note:\n","- at the beginning of the game, we have 50 frames of the game slowly zooming into the car, we should ignore this period, ie no-op during this period.\n","- there is a black bar at the bottom of the screen, we should crop this out of the observation.\n","\n","In addition, another thing to note is that the current frame doesn't give much information about the velocity and acceleration of the car, and that the car does not move much for each frame.\n","### Environment Wrapper (5 points)\n","As a result, you will need to complete `EnvWrapper` in `env_wrapper.py`. You can find more information in the docstring for the wrapper, however the main idea is that it is a wrapper to the environment that does the following:\n","- skips the first 50 frames of the game\n","- crops out the black bar and reshapes the observation to a 84x84 image, as well as turning the resulting image to grayscale\n","- performs the actions for `skip_frames` frames\n","- stacks the last `num_frames` frames together to give the agent some information about the velocity and acceleration of the car.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jBjcy-g7aFxt"},"outputs":[],"source":["from env_wrapper import EnvWrapper\n","\n","rl_test.test_wrapper(EnvWrapper)"]},{"cell_type":"markdown","metadata":{"id":"pS-EA9vkaFxt"},"source":["### CNN Model (5 points)\n","Now we are ready to build the model. Our architecture of the CNN model is the one proposed by Mnih et al in \"Human-level control through deep reinforcement learning\". Specifically this consists of the following layers:\n","- A convolutional layer with 32 filters of size 8x8 with stride 4 and relu activation\n","- A convolutional layer with 64 filters of size 4x4 with stride 2 and relu activation\n","- A convolutional layer with 64 filters of size 3x3 with stride 1 and relu activation\n","- A fully connected layer with 512 units and relu activation\n","- A fully connected layer with the number of outputs of the environment\n","\n","Please implement this model `Nature_Paper_Conv` in `model.py` as well as the helper\n","`MLP` class."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kwbZfQpZaFxt"},"outputs":[],"source":["import model\n","rl_test.test_model_DQN(model.Nature_Paper_Conv)"]},{"cell_type":"markdown","metadata":{"id":"o-gPFShiaFxu"},"source":["### DQN (40 points)\n","Now we are ready to implement the DQN algorithm.\n","\n","![title](DQN.png)\n","\n","#### Replay Buffer (5 points)\n","First start by implementing the DQN replay buffer `ReplayBufferDQN` in `buffer.py`. This buffer will store the transitions of the agent and sample them for training."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rkO4Mu-OaFxu"},"outputs":[],"source":["from replay_buffer import ReplayBufferDQN\n","\n","rl_test.test_DQN_replay_buffer(ReplayBufferDQN)"]},{"cell_type":"markdown","metadata":{"id":"D3zXTs7GaFxu"},"source":["\n","#### DQN (15 points)\n","Now implement the `_optimize_model` and `sample_action` functions in `DQN` in `DQN.py`. The `_optimize_model` function will sample a batch of transitions from the replay buffer and update the model. The `sample_action` function will sample an action from the model given the current state. Train the model over 200 episdoes, validating every 50 episodes for 30 episodes, before testing the model for 50 episodes at the end."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"e4QsqPL0Jwja"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W\u0026B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","wandb.login(key='3c00b6cca9a572530a8999ffb9ebcc3c9f921ed9')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zhjnlkwAaFxu"},"outputs":[],"source":["import DQN\n","import utils\n","import torch\n","\n","\n","trainerDQN = DQN.DQN(EnvWrapper(env),\n","                model.Nature_Paper_Conv,\n","                lr = 0.00025,\n","                gamma = 0.95,\n","                buffer_size=100000,\n","                batch_size=32,\n","                loss_fn = \"mse_loss\",\n","                use_wandb = True,\n","                device = 'cpu',\n","                seed = 42,\n","                epsilon_scheduler = utils.exponential_decay(1, 700,0.1),\n","                save_path = utils.get_save_path(\"DQN\",\"./runs/\"))\n","\n","trainerDQN.train(200,50,30,50,50)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"M_aCP655hmOO"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wEwLDpSCaFxu"},"source":["Please include a plot of the training and validation rewards over the episodes in the report. An additional question to answer is does the loss matter in DQN? Why or why not?\n","\n","We can also draw a animation of the car in one game, the code is provided below"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"70XRVh6TaFxu"},"outputs":[],"source":["eval_env = gym.make('CarRacing-v2', continuous=True, render_mode='rgb_array')\n","eval_env = EnvWrapper(eval_env)\n","\n","total_rewards, frames = trainerDQN.play_episode(0,True,42)\n","anim = animate(frames)\n","HTML(anim.to_jshtml())"]},{"cell_type":"markdown","metadata":{"id":"3YadosUeaFxu"},"source":["### Double DQN\n","In the original paper, where the algorithim is shown above, the estimated target Q value was computed using the current Q network's weights. However, this can lead to overestimation of the Q values. To mitigate this, we can use the target network to compute the target Q value. This is known as Double DQN.\n","#### Hard updating Target Network (5 points)\n","Original implementations for this involved hard updates, where the model weights were copied to the target network every C steps. This is known as hard updating. This was what was used in the Nature Paper by Mnih et al 2015 \"Human-level control through deep reinforcement learning\"\n","\n","Please implement this by implementing the `_optimize_model` and `_update_model` classes in `HardUpdateDQN` in `DQN.py`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"q7hTC29aaFxu"},"outputs":[],"source":["trainerHardUpdateDQN = DQN.HardUpdateDQN(EnvWrapper(env),\n","                model.Nature_Paper_Conv,\n","                update_freq = 100,\n","                lr = 0.00025,\n","                gamma = 0.95,\n","                buffer_size=100000,\n","                batch_size=32,\n","                loss_fn = \"mse_loss\",\n","                use_wandb = False,\n","                device = 'cuda',\n","                seed = 42,\n","                epsilon_scheduler = utils.exponential_decay(1, 1000,0.1),\n","                save_path = utils.get_save_path(\"DoubleDQN_HardUpdates/\",\"./runs/\"))\n","\n","trainerHardUpdateDQN.train(200,50,30,50,50)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iv_c8wEEaFxv"},"outputs":[],"source":["total_rewards, frames = trainerHardUpdateDQN.play_episode(0,True,42)\n","anim = animate(frames)\n","HTML(anim.to_jshtml())"]},{"cell_type":"markdown","metadata":{"id":"YGCkd_k5aFxv"},"source":["#### Soft Updates (5 points)\n","A more recent improvement is to use soft updates, also known as Polyak averaging, where the target network is updated with a small fraction of the current model weights every step. In other words:\n","$$\\theta_{target} = \\tau \\theta_{model} + (1-\\tau) \\theta_{target}$$\n","for some $\\tau \u003c\u003c 1$\n","Please implement this by implementing the `_update_model` class in `SoftUpdateDQN` in `DQN.py`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0IybDhY8aFxv"},"outputs":[],"source":["traineSoftUpdateDQN = DQN.SoftUpdateDQN(EnvWrapper(env),\n","                model.Nature_Paper_Conv,\n","                tau = 0.01,\n","                update_freq = 1,\n","                lr = 0.00025,\n","                gamma = 0.95,\n","                buffer_size=100000,\n","                batch_size=32,\n","                loss_fn = \"mse_loss\",\n","                use_wandb = False,\n","                device = 'cuda',\n","                seed = 42,\n","                epsilon_scheduler = utils.exponential_decay(1, 1000,0.1),\n","                save_path = utils.get_save_path(\"DoubleDQN_SoftUpdates\",\"./runs/\"))\n","\n","traineSoftUpdateDQN.train(200,50,30,50,50)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"r6VsRqtoaFxv"},"outputs":[],"source":["total_rewards, frames = traineSoftUpdateDQN.play_episode(0,True,42)\n","anim = animate(frames)\n","HTML(anim.to_jshtml())"]},{"cell_type":"markdown","metadata":{"id":"Te58RZOYaFxv"},"source":["#### Questions:\n","- Which method performed better? (5 points)\n","- If we modify the $\\tau$ for soft updates or the $C$ for the hard updates, how does this affect the performance of the model, come up with a intuition for this, then experimentally verify this.\n"," (5 points)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}